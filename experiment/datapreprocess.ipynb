{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\Medical QA System\\env\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone \n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 20\n",
      "Number of documents loaded: 382\n"
     ]
    }
   ],
   "source": [
    "# Reading the Dataset\n",
    "def read_doc(directory):\n",
    "    print(f\"Files in directory: {len(os.listdir(directory))}\")  # List all files\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents\n",
    "\n",
    "path = '../data/'\n",
    "doc = read_doc(path)\n",
    "print(f\"Number of documents loaded: {len(doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Divide the docs into chunks\n",
    "### https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html#\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "\n",
    "documents=chunk_data(docs=doc)\n",
    "len(documents)\n",
    "# documents[381]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding Technique Of OPENAI\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of vector embedding\n",
    "vectors=embeddings.embed_query(\"Hello, world\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Loading the data chunks to the pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_6hKpf2_MvwLm4V9pu54N9nmDmUY8MFNuaHrP43JBwLD2FEEMPjC1GhKNVc5AUmhHzobyMP\")\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "index_name=\"medicalqabot\"\n",
    "\n",
    "print(pc.Index(index_name).describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "\n",
    "for i, chunk in enumerate(documents):\n",
    "    \n",
    "    chunk_text = chunk.page_content\n",
    "    metadata = chunk.metadata  \n",
    "    # print(chunk_text, metadata)\n",
    "    embedding = embeddings.embed_query(chunk_text)\n",
    "    \n",
    "    # Store in Pinecone\n",
    "    index.upsert([(f\"doc-{i}\", embedding, metadata)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 399}},\n",
      " 'total_vector_count': 399}\n"
     ]
    }
   ],
   "source": [
    "# Checking data into the vector database after inserting the data\n",
    "print(pc.Index(index_name).describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
