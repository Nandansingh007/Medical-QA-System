{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intializing and Accessing Pinecone Database and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_components(openai_api_key, pinecone_api_key, index_name):\n",
    "    \n",
    "    \"\"\"Initialize and return core components.\"\"\"\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "    vectorstore = PineconeVectorStore(index=index, embedding=embeddings, text_key=\"text\")\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0.1, model=\"gpt-4\", openai_api_key=openai_api_key)\n",
    "    return index, vectorstore, llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-step Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_retrieval(vectorstore, question, k=4):\n",
    "    \"\"\"Simple semantic search using embeddings.\"\"\"\n",
    "    results = vectorstore.similarity_search_with_score(question, k=k)\n",
    "    return [(doc.page_content, score) for doc, score in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi stage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_retrieval(vectorstore, llm, question, k=4):\n",
    "    \"\"\"Multi-step retrieval using query decomposition.\"\"\"\n",
    "    decomposition_prompt = \"\"\"\n",
    "    Break down this medical question into 2-3 key sub-queries that would help gather comprehensive information:\n",
    "    Question: {question}\n",
    "    Return only the sub-queries, one per line.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": decomposition_prompt.format(question=question)}]\n",
    "    sub_queries = llm.invoke(messages).content.strip().split('\\n')\n",
    "\n",
    "    all_results = []\n",
    "    for sub_query in sub_queries:\n",
    "        results = vectorstore.similarity_search_with_score(sub_query, k=2)\n",
    "        all_results.extend([(doc.page_content, score, sub_query) for doc, score in results])\n",
    "\n",
    "    all_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(content, score) for content, score, _ in all_results[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept Based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_based_retrieval(vectorstore, llm, question, k=4):\n",
    "    \"\"\"Concept-based retrieval using medical concept extraction.\"\"\"\n",
    "    concept_prompt = \"\"\"\n",
    "    Extract key medical concepts from this question and reformulate as a search query:\n",
    "    Question: {question}\n",
    "    Format: List the concepts and combine them into a search query.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": concept_prompt.format(question=question)}]\n",
    "    concept_query = llm.invoke(messages).content\n",
    "\n",
    "    results = vectorstore.similarity_search_with_score(concept_query, k=k)\n",
    "    return [(doc.page_content, score) for doc, score in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieval(vectorstore, llm, question, k=4):\n",
    "    \"\"\"Combine semantic and concept-based retrieval.\"\"\"\n",
    "    semantic_results = single_step_retrieval(vectorstore, question, k=k//2)\n",
    "    concept_results = concept_based_retrieval(vectorstore, llm, question, k=k//2)\n",
    "\n",
    "    all_results = semantic_results + concept_results\n",
    "    seen_contents = set()\n",
    "    unique_results = []\n",
    "\n",
    "    for content, score in all_results:\n",
    "        if content not in seen_contents:\n",
    "            seen_contents.add(content)\n",
    "            unique_results.append((content, score))\n",
    "\n",
    "    return sorted(unique_results, key=lambda x: x[1], reverse=True)[:k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting Each Retrieval Strategies and saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(openai_api_key, pinecone_api_key, index_name, question, options):\n",
    "    \"\"\"Run and compare all retrieval strategies.\"\"\"\n",
    "    index, vectorstore, llm = initialize_components(openai_api_key, pinecone_api_key, index_name)\n",
    "\n",
    "    experiments = {\n",
    "        \"single_step\": {\n",
    "            \"results\": single_step_retrieval(vectorstore, question),\n",
    "            \"method\": \"Simple semantic search\"\n",
    "        },\n",
    "        \"multi_step\": {\n",
    "            \"results\": multi_step_retrieval(vectorstore, llm, question),\n",
    "            \"method\": \"Query decomposition and multi-step retrieval\"\n",
    "        },\n",
    "        \"concept_based\": {\n",
    "            \"results\": concept_based_retrieval(vectorstore, llm, question),\n",
    "            \"method\": \"Medical concept extraction and search\"\n",
    "        },\n",
    "        \"hybrid\": {\n",
    "            \"results\": hybrid_retrieval(vectorstore, llm, question),\n",
    "            \"method\": \"Combined semantic and concept-based approach\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"retrieval_experiments_{timestamp}.json\"\n",
    "\n",
    "    results = {\n",
    "        \"question\": question,\n",
    "        \"options\": options,\n",
    "        \"experiments\": experiments\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nResults saved to: {filename}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the retrieval experiment.\"\"\"\n",
    "    sample_mcq = {\n",
    "        \"question\": \"A 32-year-old male patient with a history of substance abuse disorder (heroin) has presented with severe toothache for the last three days. His medical history reveals he is in active treatment for substance use disorder and he has been maintaining a drug-free lifestyle for the past six months. He's currently having a severe dental abscess in the lower right second molar confirmed by dental radiography. How would you manage his condition?\",\n",
    "        \"options\": [\n",
    "            \"A) Prescribe opioids for pain relief\",\n",
    "            \"B) Consult with the patient's addiction specialist before prescribing opioids for pain management\",\n",
    "            \"C) Prescribe non-opioid analgesics and refer the patient to a dental surgeon for abscess management\",\n",
    "            \"D) Ignore the patient's request for pain relief due to his substance abuse history\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    results = run_experiment(\n",
    "        openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        pinecone_api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
    "        index_name=\"medicalqabot\",\n",
    "        question=sample_mcq[\"question\"],\n",
    "        options=sample_mcq[\"options\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nExperiment Summary:\")\n",
    "    for method, data in results[\"experiments\"].items():\n",
    "        print(f\"\\n{method.replace('_', ' ').title()}:\")\n",
    "        print(f\"Number of documents retrieved: {len(data['results'])}\")\n",
    "        print(f\"Top document similarity score: {data['results'][0][1] if data['results'] else 'N/A'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_39800\\490913642.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_39800\\490913642.py:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.1, model=\"gpt-4\", openai_api_key=openai_api_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: retrieval_experiments_20250112_224045.json\n",
      "\n",
      "Experiment Summary:\n",
      "\n",
      "Single Step:\n",
      "Number of documents retrieved: 4\n",
      "Top document similarity score: 0.8422038\n",
      "\n",
      "Multi Step:\n",
      "Number of documents retrieved: 4\n",
      "Top document similarity score: 0.85318786\n",
      "\n",
      "Concept Based:\n",
      "Number of documents retrieved: 4\n",
      "Top document similarity score: 0.83429736\n",
      "\n",
      "Hybrid:\n",
      "Number of documents retrieved: 3\n",
      "Top document similarity score: 0.8422038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
